\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=4cm]{geometry}
\usepackage{scalerel}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{xspace}
\usepackage{url}
\usepackage{lmodern}

\definecolor{myblue}{rgb}{0.33,0.61,0.83}
\definecolor{mygreen}{rgb}{0.39,0.56,0.31}
\definecolor{myorange}{rgb}{0.80,0.56,0.47}

\lstset{
	basicstyle=\ttfamily,
	backgroundcolor=\color{gray!10!white},
    xleftmargin=6pt,
	framexleftmargin=6pt,
	xrightmargin=6pt,
    framexrightmargin=6pt,
    framextopmargin=6pt,
	framexbottommargin=6pt,
    frame=tb,
	framerule=0pt,
	columns=fullflexible,
	breaklines=true,
	tabsize=2,
	commentstyle=\color{mygreen},
	keywordstyle=\color{myblue},
	stringstyle=\color{myorange}
}

\setlength{\headheight}{50pt}
\setlength\parindent{0pt}

\lhead{\includegraphics[scale=0.8]{logo-mse.png} \vspace{8pt}}

\rhead{\textbf{Lab 1: Crawling, indexation and webpage research} \\ 
Romain Claret and Jonathan Rial \\ 
Web Mining}

\cfoot{Page \thepage\ / \pageref{LastPage}}

\pagestyle{fancy}

\begin{document}

\part*{Lab 1: Crawling, indexation and webpage research}
During this web mining laboratory, we explored the website crawling with Crawler4j and its indexation with Solr via jsoup, which is HTML parser. We finally used the indexation to perform searches.\\

We used docker-solr as docker image for our Solr.

\section{Crawler}
\subsection{Core}
We started by creating a core for Solr, named \textit{core\_one} using the following commands:\\

\begin{lstlisting}[language=sh]
$ docker exec -u 0 -it docker-solr bash to attach to the docker bash
\end{lstlisting}

then

\begin{lstlisting}[language=sh]
$ bin/solr create -c core_one to create a default core.properties
\end{lstlisting}

As we set \textit{update.autoCreateFields} to \textbf{false} in our core. We had to create two custom fields: \textit{doc\_title\_en} and \textit{doc\_body\_en}, which will be used to store the title and the body of each retained pages by the crawler.
\\
\subsection{Crawler4j}
We configured our crawler, \textit{MyCrawler.java} to work with our Solr core \textit{core\_one}. Concerning our first crawler configuration:\\

\begin{itemize}  
\item starting page: wikipedia.org at "Veganism" page
\item domain limitation: yes
\item maximum pages to fetch: 70
\item maximum deepness: 3
\item politeness delay: 500
\item https: yes
\item FILTERS: custom binary files
\end{itemize}

\subsubsection{shouldVisit function}
We are applying the \textbf{FILTERS} pattern matching on the URL and verify that the domain.

\subsubsection{visit function}

The crawler retrieves the HTML page and parses them with jSoup. It creates a Solr document with the id field (hashcode of the page), the \textit{doc\_title\_en} (title from the page), and \textit{doc\_body\_en} (body content from the page) and finally adds the document into the current Solr instance.

To avoid Solr overloads, we set a loader for the commits. Indeed, the program will stock 50 documents before committing them to the Solr as a batch.

Each visited page has its content indexed by Solr.

\subsection{Tries and fails}
\begin{itemize}  
\item We first indexed \textbf{Vegan.com}, but the pages were not meaningful from a feature point of view, indeed it had no categories.
\item We then indexed  \textbf{arxiv.org}, but their \textit{"robots.txt"} policy was not allowing us to go anywhere.
\end{itemize}

\section{Specific Indexation}


\section{Research}


\section{Theorical questions}
\subsection{Please explain what strategy should be adopted for indexing pages in several languages (each page is composed of only one language, but the corpus includes pages in several languages). What should you watch out for? Please explain the process you propose.}


\subsection{Solr allows by default to do a fuzzy search. Please explain what it is and how Solr implements it. Some first names may have a lot of spelling variations (eg Caitlin : Caitilin, Caitlen, Caitlinn, Caitlyn, Caitlyne, Caitlynn, Cateline, Catelinn, Catelyn, Catelynn, Catlain, Catlin, Catline, Catlyn, Catlynn, Kaitlin, Kaitlinn, Kaitlyn, Kaitlynn, Katelin, Katelyn, Katelynn, etc). Is it possible to use, while keeping a good performance, the fuzzy research made available by Solr to do research taking into account such variations? If not what alternative(s) do you see, please justify your answer.}

\end{document}

